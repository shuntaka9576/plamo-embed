import torch
import torch.nn.functional as F
from transformers import AutoModel, AutoTokenizer

# ğŸ¤— Huggingface Hubã‹ã‚‰ä»¥ä¸‹ã®ã‚ˆã†ã«ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™
tokenizer = AutoTokenizer.from_pretrained(
    "pfnet/plamo-embedding-1b", trust_remote_code=True
)
model = AutoModel.from_pretrained("pfnet/plamo-embedding-1b", trust_remote_code=True)

device = "cuda" if torch.cuda.is_available() else "cpu"
model = model.to(device)

query = "PLaMo-Embedding-1Bã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"
documents = [
    "PLaMo-Embedding-1Bã¯ã€Preferred Networks, Inc. ã«ã‚ˆã£ã¦é–‹ç™ºã•ã‚ŒãŸæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚",
    "æœ€è¿‘ã¯éšåˆ†ã¨æš–ã‹ããªã‚Šã¾ã—ãŸã­ã€‚",
]

with torch.inference_mode():
    # æƒ…å ±æ¤œç´¢ã«ãŠã‘ã‚‹ã‚¯ã‚¨ãƒªæ–‡ç« ã®åŸ‹ã‚è¾¼ã¿ã«é–¢ã—ã¦ã¯ã€`encode_query` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ãã ã•ã„
    # tokenizerã‚‚æ¸¡ã™å¿…è¦ãŒã‚ã‚Šã¾ã™
    query_embedding = model.encode_query(query, tokenizer)
    # ãã‚Œä»¥å¤–ã®æ–‡ç« ã«é–¢ã—ã¦ã¯ã€ `encode_document` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ãã ã•ã„
    # æƒ…å ±æ¤œç´¢ä»¥å¤–ã®ç”¨é€”ã«ã¤ã„ã¦ã‚‚ã€ `encode_document` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ãã ã•ã„
    document_embeddings = model.encode_document(documents, tokenizer)

# ãƒ¢ãƒ‡ãƒ«ã«æ–‡ç« ã‚’å…¥åŠ›ã—ã¦å¾—ã‚‰ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«é–“ã®é¡ä¼¼åº¦ã¯ã€è¿‘ã„æ–‡ç« ã¯é«˜ãã€é ã„æ–‡ç« ã¯ä½ããªã‚Šã¾ã™
# ã“ã®æ€§è³ªã‚’ç”¨ã„ã¦æƒ…å ±æ¤œç´¢ãªã©ã«æ´»ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™
similarities = F.cosine_similarity(query_embedding, document_embeddings)
print(similarities)
